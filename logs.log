C:\Users\nikit\Anaconda3\envs\deppLearning\python.exe K:/test_task/main.py
C:\Users\nikit\Anaconda3\envs\deppLearning\lib\site-packages\sklearn\externals\joblib\externals\cloudpickle\cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
Using TensorFlow backend.
                   f0        f1    ...        f1610     f1611
sample_id                          ...
sample_1095  0.091850  0.123983    ...    -0.017975 -0.014362
sample_1096 -0.032633 -0.112829    ...     0.114378  0.109647
sample_1097  0.111977  0.315902    ...     0.021100  0.034766
sample_1098 -0.087085 -0.162212    ...    -0.102849 -0.090828
sample_1099 -0.032908  0.019606    ...     0.059336  0.063292
sample_1100  0.042498 -0.049979    ...    -0.238353 -0.593998
sample_1101 -0.079641 -0.162212    ...     0.079504  0.104893
sample_1102 -0.024775 -0.024165    ...     0.023621  0.036351
sample_1103  0.040017  0.253052    ...     0.069000  0.094988
sample_1104 -0.029875  0.040930    ...     0.040848  0.037936
sample_1105  0.005553 -0.145377    ...    -0.142765 -0.149861
sample_1106  0.067864  0.011750    ...    -0.125538 -0.132032
sample_1107  0.165465  0.315902    ...    -0.625118 -0.593998
sample_1108 -0.032770  0.113882    ...    -0.033942 -0.029418
sample_1109  0.244318  0.305801    ...    -0.200958 -0.593998
sample_1110 -0.023672 -0.037633    ...     0.209756  0.230091
sample_1111  0.135137  0.208158    ...     0.055974  0.080725
sample_1112  0.072275  0.153164    ...    -0.625118 -0.593998
sample_1113 -0.026567  0.042053    ...     0.202613  0.230884
sample_1114 -0.030151  0.072356    ...    -0.088563 -0.084885
sample_1115 -0.073300 -0.104973    ...     0.037487 -0.020305
sample_1116 -0.039663  0.019606    ...     0.002193  0.018522
sample_1117 -0.025602  0.072356    ...     0.191689  0.220582
sample_1118 -0.034838 -0.036511    ...     0.204294  0.223752
sample_1119 -0.051932 -0.009575    ...     0.072361  0.049029
sample_1120  0.204616  0.113882    ...    -0.014194  0.010598
sample_1121 -0.063512 -0.093750    ...    -0.625118 -0.593998
sample_1122  0.005415  0.192446    ...    -0.061252 -0.044869
sample_1123 -0.018158  0.207036    ...    -0.625118 -0.593998
sample_1124  0.035744  0.009505    ...     0.103453  0.132627
...               ...       ...    ...          ...       ...
sample_1259 -0.059101 -0.064569    ...     0.100092  0.114006
sample_1260 -0.006302  0.084702    ...     0.247151  0.264956
sample_1261  0.899405  0.121739    ...    -0.075958 -0.071811
sample_1262  0.013135  0.167754    ...     0.374882  0.406002
sample_1263 -0.099768 -0.185781    ...    -0.092765 -0.078942
sample_1264 -0.036906 -0.136398    ...     0.138327  0.154418
sample_1265  0.058765  0.182345    ...    -0.079320 -0.076565
sample_1266 -0.082122 -0.128542    ...    -0.111252 -0.096375
sample_1267 -0.054000 -0.048856    ...     0.082445  0.096969
sample_1268 -0.003132  0.097047    ...     0.106395  0.094988
sample_1269 -0.021191  0.061133    ...     0.137487  0.144116
sample_1270  0.109772  0.211525    ...    -0.135622 -0.164124
sample_1271 -0.034838 -0.036511    ...     0.172361  0.193641
sample_1272 -0.039112 -0.173435    ...     0.076563  0.092611
sample_1273 -0.001202 -0.106095    ...     0.133285  0.161153
sample_1274 -0.072610 -0.054468    ...    -0.041505 -0.029418
sample_1275 -0.058274 -0.026410    ...    -0.625118 -0.593998
sample_1276 -0.025602  0.089191    ...    -0.015454  0.014956
sample_1277 -0.076884 -0.115074    ...    -0.160832 -0.144711
sample_1278  0.031746 -0.018553    ...     0.069420  0.087064
sample_1279 -0.008508 -0.092627    ...     0.134966  0.156795
sample_1280 -0.087085 -0.126297    ...    -0.147387 -0.139956
sample_1281 -0.060204 -0.113952    ...     0.087487  0.106478
sample_1282 -0.028497 -0.106095    ...     0.114378  0.109647
sample_1283 -0.036217  0.020728    ...     0.198411  0.223752
sample_1284 -0.037457  0.001649    ...     0.009756  0.006240
sample_1285 -0.021742 -0.008452    ...     0.044210  0.037143
sample_1286  0.001969 -0.048856    ...    -0.010832  0.016541
sample_1287 -0.069716 -0.118441    ...     0.042109  0.052199
sample_1288 -0.091221 -0.214962    ...    -0.165454 -0.175614

[194 rows x 1612 columns]
data_test length : (876, 1612)
data_train length : (219, 1612)
y_data_test length : (876,)
y_data_train length : (219,)
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input1 (InputLayer)          (None, 1612)              0
_________________________________________________________________
dense_1 (Dense)              (None, 8)                 12904
_________________________________________________________________
dropout_1 (Dropout)          (None, 8)                 0
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 9
=================================================================
Total params: 12,913
Trainable params: 12,913
Non-trainable params: 0
_________________________________________________________________
Train on 876 samples, validate on 219 samples
Epoch 1/20
2019-03-17 19:29:08.635346: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2019-03-17 19:29:08.906189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties:
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:0a:00.0
totalMemory: 8.00GiB freeMemory: 6.62GiB
2019-03-17 19:29:08.906466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-17 19:29:09.440003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-17 19:29:09.440166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0
2019-03-17 19:29:09.440270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N
2019-03-17 19:29:09.440508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6373 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)

  5/876 [..............................] - ETA: 4:28 - loss: 0.6931 - acc: 0.4000
100/876 [==>...........................] - ETA: 12s - loss: 0.6926 - acc: 0.6100
195/876 [=====>........................] - ETA: 5s - loss: 0.6920 - acc: 0.6154
290/876 [========>.....................] - ETA: 3s - loss: 0.6922 - acc: 0.5897
385/876 [============>.................] - ETA: 2s - loss: 0.6915 - acc: 0.6000
485/876 [===============>..............] - ETA: 1s - loss: 0.6908 - acc: 0.6082
580/876 [==================>...........] - ETA: 0s - loss: 0.6899 - acc: 0.6172
675/876 [======================>.......] - ETA: 0s - loss: 0.6899 - acc: 0.6089
765/876 [=========================>....] - ETA: 0s - loss: 0.6895 - acc: 0.6105
860/876 [============================>.] - ETA: 0s - loss: 0.6892 - acc: 0.6081
876/876 [==============================] - 2s 2ms/step - loss: 0.6893 - acc: 0.6062 - val_loss: 0.6837 - val_acc: 0.6347
Epoch 2/20

  5/876 [..............................] - ETA: 0s - loss: 0.6863 - acc: 0.6000
100/876 [==>...........................] - ETA: 0s - loss: 0.6854 - acc: 0.6100
195/876 [=====>........................] - ETA: 0s - loss: 0.6881 - acc: 0.5744
290/876 [========>.....................] - ETA: 0s - loss: 0.6867 - acc: 0.5897
385/876 [============>.................] - ETA: 0s - loss: 0.6867 - acc: 0.5870
475/876 [===============>..............] - ETA: 0s - loss: 0.6840 - acc: 0.6126
560/876 [==================>...........] - ETA: 0s - loss: 0.6846 - acc: 0.6054
645/876 [=====================>........] - ETA: 0s - loss: 0.6851 - acc: 0.5984
735/876 [========================>.....] - ETA: 0s - loss: 0.6846 - acc: 0.6014
825/876 [===========================>..] - ETA: 0s - loss: 0.6836 - acc: 0.6073
876/876 [==============================] - 1s 606us/step - loss: 0.6835 - acc: 0.6073 - val_loss: 0.6774 - val_acc: 0.6347
Epoch 3/20

  5/876 [..............................] - ETA: 0s - loss: 0.6821 - acc: 0.6000
 95/876 [==>...........................] - ETA: 0s - loss: 0.6775 - acc: 0.6316
180/876 [=====>........................] - ETA: 0s - loss: 0.6801 - acc: 0.6111
265/876 [========>.....................] - ETA: 0s - loss: 0.6775 - acc: 0.6264
350/876 [==========>...................] - ETA: 0s - loss: 0.6778 - acc: 0.6229
440/876 [==============>...............] - ETA: 0s - loss: 0.6776 - acc: 0.6227
530/876 [=================>............] - ETA: 0s - loss: 0.6805 - acc: 0.6038
620/876 [====================>.........] - ETA: 0s - loss: 0.6801 - acc: 0.6048
715/876 [=======================>......] - ETA: 0s - loss: 0.6789 - acc: 0.6112
810/876 [==========================>...] - ETA: 0s - loss: 0.6793 - acc: 0.6074
876/876 [==============================] - 1s 612us/step - loss: 0.6792 - acc: 0.6073 - val_loss: 0.6725 - val_acc: 0.6347
Epoch 4/20

  5/876 [..............................] - ETA: 0s - loss: 0.6419 - acc: 0.8000
 95/876 [==>...........................] - ETA: 0s - loss: 0.6789 - acc: 0.6000
190/876 [=====>........................] - ETA: 0s - loss: 0.6778 - acc: 0.6053
285/876 [========>.....................] - ETA: 0s - loss: 0.6780 - acc: 0.6035
385/876 [============>.................] - ETA: 0s - loss: 0.6760 - acc: 0.6130
480/876 [===============>..............] - ETA: 0s - loss: 0.6751 - acc: 0.6167
570/876 [==================>...........] - ETA: 0s - loss: 0.6770 - acc: 0.6070
660/876 [=====================>........] - ETA: 0s - loss: 0.6761 - acc: 0.6106
755/876 [========================>.....] - ETA: 0s - loss: 0.6759 - acc: 0.6106
845/876 [===========================>..] - ETA: 0s - loss: 0.6752 - acc: 0.6130
876/876 [==============================] - 1s 602us/step - loss: 0.6765 - acc: 0.6073 - val_loss: 0.6690 - val_acc: 0.6347
Epoch 5/20

  5/876 [..............................] - ETA: 0s - loss: 0.7222 - acc: 0.4000
 95/876 [==>...........................] - ETA: 0s - loss: 0.6793 - acc: 0.5895
185/876 [=====>........................] - ETA: 0s - loss: 0.6781 - acc: 0.5946
270/876 [========>.....................] - ETA: 0s - loss: 0.6811 - acc: 0.5815
360/876 [===========>..................] - ETA: 0s - loss: 0.6787 - acc: 0.5917
455/876 [==============>...............] - ETA: 0s - loss: 0.6788 - acc: 0.5912
550/876 [=================>............] - ETA: 0s - loss: 0.6766 - acc: 0.6000
640/876 [====================>.........] - ETA: 0s - loss: 0.6754 - acc: 0.6047
725/876 [=======================>......] - ETA: 0s - loss: 0.6748 - acc: 0.6069
810/876 [==========================>...] - ETA: 0s - loss: 0.6743 - acc: 0.6086
876/876 [==============================] - 1s 615us/step - loss: 0.6746 - acc: 0.6073 - val_loss: 0.6666 - val_acc: 0.6347
Epoch 6/20

  5/876 [..............................] - ETA: 0s - loss: 0.6239 - acc: 0.8000
 90/876 [==>...........................] - ETA: 0s - loss: 0.6726 - acc: 0.6111
180/876 [=====>........................] - ETA: 0s - loss: 0.6696 - acc: 0.6222
270/876 [========>.....................] - ETA: 0s - loss: 0.6685 - acc: 0.6259
360/876 [===========>..................] - ETA: 0s - loss: 0.6655 - acc: 0.6361
450/876 [==============>...............] - ETA: 0s - loss: 0.6623 - acc: 0.6467
540/876 [=================>............] - ETA: 0s - loss: 0.6627 - acc: 0.6444
630/876 [====================>.........] - ETA: 0s - loss: 0.6654 - acc: 0.6349
725/876 [=======================>......] - ETA: 0s - loss: 0.6678 - acc: 0.6262
815/876 [==========================>...] - ETA: 0s - loss: 0.6715 - acc: 0.6135
876/876 [==============================] - 1s 611us/step - loss: 0.6732 - acc: 0.6073 - val_loss: 0.6644 - val_acc: 0.6347
Epoch 7/20

  5/876 [..............................] - ETA: 0s - loss: 0.6746 - acc: 0.6000
 95/876 [==>...........................] - ETA: 0s - loss: 0.6808 - acc: 0.5789
190/876 [=====>........................] - ETA: 0s - loss: 0.6762 - acc: 0.5947
280/876 [========>.....................] - ETA: 0s - loss: 0.6705 - acc: 0.6143
365/876 [===========>..................] - ETA: 0s - loss: 0.6706 - acc: 0.6137
455/876 [==============>...............] - ETA: 0s - loss: 0.6687 - acc: 0.6198
550/876 [=================>............] - ETA: 0s - loss: 0.6719 - acc: 0.6091
640/876 [====================>.........] - ETA: 0s - loss: 0.6693 - acc: 0.6172
735/876 [========================>.....] - ETA: 0s - loss: 0.6725 - acc: 0.6068
825/876 [===========================>..] - ETA: 0s - loss: 0.6715 - acc: 0.6097
876/876 [==============================] - 1s 599us/step - loss: 0.6722 - acc: 0.6073 - val_loss: 0.6632 - val_acc: 0.6347
Epoch 8/20

  5/876 [..............................] - ETA: 0s - loss: 0.6740 - acc: 0.6000
100/876 [==>...........................] - ETA: 0s - loss: 0.6897 - acc: 0.5500
195/876 [=====>........................] - ETA: 0s - loss: 0.6789 - acc: 0.5846
285/876 [========>.....................] - ETA: 0s - loss: 0.6862 - acc: 0.5614
375/876 [===========>..................] - ETA: 0s - loss: 0.6808 - acc: 0.5787
455/876 [==============>...............] - ETA: 0s - loss: 0.6837 - acc: 0.5692
535/876 [=================>............] - ETA: 0s - loss: 0.6817 - acc: 0.5757
620/876 [====================>.........] - ETA: 0s - loss: 0.6812 - acc: 0.5774
700/876 [======================>.......] - ETA: 0s - loss: 0.6772 - acc: 0.5900
785/876 [=========================>....] - ETA: 0s - loss: 0.6735 - acc: 0.6013
870/876 [============================>.] - ETA: 0s - loss: 0.6713 - acc: 0.6080
876/876 [==============================] - 1s 641us/step - loss: 0.6715 - acc: 0.6073 - val_loss: 0.6620 - val_acc: 0.6347
Epoch 9/20

  5/876 [..............................] - ETA: 0s - loss: 0.5396 - acc: 1.0000
 80/876 [=>............................] - ETA: 0s - loss: 0.6651 - acc: 0.6250
160/876 [====>.........................] - ETA: 0s - loss: 0.6736 - acc: 0.6000
240/876 [=======>......................] - ETA: 0s - loss: 0.6707 - acc: 0.6083
315/876 [=========>....................] - ETA: 0s - loss: 0.6648 - acc: 0.6254
390/876 [============>.................] - ETA: 0s - loss: 0.6683 - acc: 0.6154
475/876 [===============>..............] - ETA: 0s - loss: 0.6692 - acc: 0.6126
565/876 [==================>...........] - ETA: 0s - loss: 0.6736 - acc: 0.6000
655/876 [=====================>........] - ETA: 0s - loss: 0.6730 - acc: 0.6015
740/876 [========================>.....] - ETA: 0s - loss: 0.6745 - acc: 0.5973
835/876 [===========================>..] - ETA: 0s - loss: 0.6731 - acc: 0.6012
876/876 [==============================] - 1s 666us/step - loss: 0.6710 - acc: 0.6073 - val_loss: 0.6612 - val_acc: 0.6347
Epoch 10/20

  5/876 [..............................] - ETA: 0s - loss: 0.7437 - acc: 0.4000
100/876 [==>...........................] - ETA: 0s - loss: 0.6839 - acc: 0.5700
195/876 [=====>........................] - ETA: 0s - loss: 0.6624 - acc: 0.6308
285/876 [========>.....................] - ETA: 0s - loss: 0.6544 - acc: 0.6526
375/876 [===========>..................] - ETA: 0s - loss: 0.6580 - acc: 0.6427
465/876 [==============>...............] - ETA: 0s - loss: 0.6561 - acc: 0.6473
560/876 [==================>...........] - ETA: 0s - loss: 0.6670 - acc: 0.6179
655/876 [=====================>........] - ETA: 0s - loss: 0.6708 - acc: 0.6076
750/876 [========================>.....] - ETA: 0s - loss: 0.6740 - acc: 0.5987
840/876 [===========================>..] - ETA: 0s - loss: 0.6730 - acc: 0.6012
876/876 [==============================] - 1s 594us/step - loss: 0.6708 - acc: 0.6073 - val_loss: 0.6606 - val_acc: 0.6347
Epoch 11/20

  5/876 [..............................] - ETA: 0s - loss: 0.5275 - acc: 1.0000
100/876 [==>...........................] - ETA: 0s - loss: 0.6587 - acc: 0.6400
190/876 [=====>........................] - ETA: 0s - loss: 0.6675 - acc: 0.6158
280/876 [========>.....................] - ETA: 0s - loss: 0.6587 - acc: 0.6393
375/876 [===========>..................] - ETA: 0s - loss: 0.6594 - acc: 0.6373
470/876 [===============>..............] - ETA: 0s - loss: 0.6670 - acc: 0.6170
565/876 [==================>...........] - ETA: 0s - loss: 0.6727 - acc: 0.6018
660/876 [=====================>........] - ETA: 0s - loss: 0.6727 - acc: 0.6015
755/876 [========================>.....] - ETA: 0s - loss: 0.6743 - acc: 0.5974
850/876 [============================>.] - ETA: 0s - loss: 0.6715 - acc: 0.6047
876/876 [==============================] - 1s 590us/step - loss: 0.6705 - acc: 0.6073 - val_loss: 0.6601 - val_acc: 0.6347
Epoch 12/20

  5/876 [..............................] - ETA: 0s - loss: 0.7481 - acc: 0.4000
100/876 [==>...........................] - ETA: 0s - loss: 0.6807 - acc: 0.5800
195/876 [=====>........................] - ETA: 0s - loss: 0.6828 - acc: 0.5744
290/876 [========>.....................] - ETA: 0s - loss: 0.6925 - acc: 0.5483
385/876 [============>.................] - ETA: 0s - loss: 0.6888 - acc: 0.5584
475/876 [===============>..............] - ETA: 0s - loss: 0.6866 - acc: 0.5642
565/876 [==================>...........] - ETA: 0s - loss: 0.6825 - acc: 0.5752
660/876 [=====================>........] - ETA: 0s - loss: 0.6716 - acc: 0.6045
755/876 [========================>.....] - ETA: 0s - loss: 0.6698 - acc: 0.6093
845/876 [===========================>..] - ETA: 0s - loss: 0.6692 - acc: 0.6107
876/876 [==============================] - 1s 594us/step - loss: 0.6705 - acc: 0.6073 - val_loss: 0.6595 - val_acc: 0.6347
Epoch 13/20

  5/876 [..............................] - ETA: 0s - loss: 0.5948 - acc: 0.8000
100/876 [==>...........................] - ETA: 0s - loss: 0.6574 - acc: 0.6400
190/876 [=====>........................] - ETA: 0s - loss: 0.6669 - acc: 0.6158
285/876 [========>.....................] - ETA: 0s - loss: 0.6690 - acc: 0.6105
375/876 [===========>..................] - ETA: 0s - loss: 0.6689 - acc: 0.6107
470/876 [===============>..............] - ETA: 0s - loss: 0.6706 - acc: 0.6064
565/876 [==================>...........] - ETA: 0s - loss: 0.6682 - acc: 0.6124
655/876 [=====================>........] - ETA: 0s - loss: 0.6695 - acc: 0.6092
750/876 [========================>.....] - ETA: 0s - loss: 0.6683 - acc: 0.6120
845/876 [===========================>..] - ETA: 0s - loss: 0.6693 - acc: 0.6095
876/876 [==============================] - 1s 588us/step - loss: 0.6702 - acc: 0.6073 - val_loss: 0.6592 - val_acc: 0.6347
Epoch 14/20

  5/876 [..............................] - ETA: 0s - loss: 0.7524 - acc: 0.4000
100/876 [==>...........................] - ETA: 0s - loss: 0.6810 - acc: 0.5800
195/876 [=====>........................] - ETA: 0s - loss: 0.6731 - acc: 0.6000
290/876 [========>.....................] - ETA: 0s - loss: 0.6813 - acc: 0.5793
380/876 [============>.................] - ETA: 0s - loss: 0.6732 - acc: 0.6000
475/876 [===============>..............] - ETA: 0s - loss: 0.6740 - acc: 0.5979
565/876 [==================>...........] - ETA: 0s - loss: 0.6731 - acc: 0.6000
655/876 [=====================>........] - ETA: 0s - loss: 0.6689 - acc: 0.6107
755/876 [========================>.....] - ETA: 0s - loss: 0.6694 - acc: 0.6093
845/876 [===========================>..] - ETA: 0s - loss: 0.6689 - acc: 0.6107
876/876 [==============================] - 1s 601us/step - loss: 0.6702 - acc: 0.6073 - val_loss: 0.6590 - val_acc: 0.6347
Epoch 15/20

  5/876 [..............................] - ETA: 0s - loss: 0.5922 - acc: 0.8000
 95/876 [==>...........................] - ETA: 0s - loss: 0.6731 - acc: 0.6000
180/876 [=====>........................] - ETA: 0s - loss: 0.6775 - acc: 0.5889
270/876 [========>.....................] - ETA: 0s - loss: 0.6731 - acc: 0.6000
355/876 [===========>..................] - ETA: 0s - loss: 0.6776 - acc: 0.5887
445/876 [==============>...............] - ETA: 0s - loss: 0.6667 - acc: 0.6157
535/876 [=================>............] - ETA: 0s - loss: 0.6609 - acc: 0.6299
615/876 [====================>.........] - ETA: 0s - loss: 0.6659 - acc: 0.6179
700/876 [======================>.......] - ETA: 0s - loss: 0.6673 - acc: 0.6143
785/876 [=========================>....] - ETA: 0s - loss: 0.6700 - acc: 0.6076
875/876 [============================>.] - ETA: 0s - loss: 0.6704 - acc: 0.6069
876/876 [==============================] - 1s 629us/step - loss: 0.6702 - acc: 0.6073 - val_loss: 0.6588 - val_acc: 0.6347
Epoch 16/20

  5/876 [..............................] - ETA: 0s - loss: 0.5911 - acc: 0.8000
100/876 [==>...........................] - ETA: 0s - loss: 0.6935 - acc: 0.5500
190/876 [=====>........................] - ETA: 0s - loss: 0.6987 - acc: 0.5368
285/876 [========>.....................] - ETA: 0s - loss: 0.7014 - acc: 0.5298
380/876 [============>.................] - ETA: 0s - loss: 0.6828 - acc: 0.5763
470/876 [===============>..............] - ETA: 0s - loss: 0.6827 - acc: 0.5766
565/876 [==================>...........] - ETA: 0s - loss: 0.6797 - acc: 0.5841
655/876 [=====================>........] - ETA: 0s - loss: 0.6781 - acc: 0.5878
750/876 [========================>.....] - ETA: 0s - loss: 0.6742 - acc: 0.5973
840/876 [===========================>..] - ETA: 0s - loss: 0.6707 - acc: 0.6060
876/876 [==============================] - 1s 594us/step - loss: 0.6701 - acc: 0.6073 - val_loss: 0.6587 - val_acc: 0.6347
Epoch 17/20

  5/876 [..............................] - ETA: 0s - loss: 0.7558 - acc: 0.4000
100/876 [==>...........................] - ETA: 0s - loss: 0.6855 - acc: 0.5700
195/876 [=====>........................] - ETA: 0s - loss: 0.6794 - acc: 0.5846
290/876 [========>.....................] - ETA: 0s - loss: 0.6687 - acc: 0.6103
380/876 [============>.................] - ETA: 0s - loss: 0.6609 - acc: 0.6289
475/876 [===============>..............] - ETA: 0s - loss: 0.6625 - acc: 0.6253
570/876 [==================>...........] - ETA: 0s - loss: 0.6597 - acc: 0.6316
665/876 [=====================>........] - ETA: 0s - loss: 0.6623 - acc: 0.6256
760/876 [=========================>....] - ETA: 0s - loss: 0.6665 - acc: 0.6158
850/876 [============================>.] - ETA: 0s - loss: 0.6692 - acc: 0.6094
876/876 [==============================] - 1s 591us/step - loss: 0.6701 - acc: 0.6073 - val_loss: 0.6584 - val_acc: 0.6347
Epoch 18/20

  5/876 [..............................] - ETA: 0s - loss: 0.5885 - acc: 0.8000
 95/876 [==>...........................] - ETA: 0s - loss: 0.6598 - acc: 0.6316
190/876 [=====>........................] - ETA: 0s - loss: 0.6576 - acc: 0.6368
285/876 [========>.....................] - ETA: 0s - loss: 0.6717 - acc: 0.6035
380/876 [============>.................] - ETA: 0s - loss: 0.6753 - acc: 0.5947
470/876 [===============>..............] - ETA: 0s - loss: 0.6722 - acc: 0.6021
560/876 [==================>...........] - ETA: 0s - loss: 0.6768 - acc: 0.5911
655/876 [=====================>........] - ETA: 0s - loss: 0.6744 - acc: 0.5969
745/876 [========================>.....] - ETA: 0s - loss: 0.6726 - acc: 0.6013
840/876 [===========================>..] - ETA: 0s - loss: 0.6701 - acc: 0.6071
876/876 [==============================] - 1s 591us/step - loss: 0.6701 - acc: 0.6073 - val_loss: 0.6584 - val_acc: 0.6347
Epoch 19/20

  5/876 [..............................] - ETA: 0s - loss: 0.5889 - acc: 0.8000
100/876 [==>...........................] - ETA: 0s - loss: 0.6773 - acc: 0.5900
195/876 [=====>........................] - ETA: 0s - loss: 0.6688 - acc: 0.6103
285/876 [========>.....................] - ETA: 0s - loss: 0.6701 - acc: 0.6070
380/876 [============>.................] - ETA: 0s - loss: 0.6664 - acc: 0.6158
475/876 [===============>..............] - ETA: 0s - loss: 0.6623 - acc: 0.6253
570/876 [==================>...........] - ETA: 0s - loss: 0.6626 - acc: 0.6246
660/876 [=====================>........] - ETA: 0s - loss: 0.6706 - acc: 0.6061
750/876 [========================>.....] - ETA: 0s - loss: 0.6709 - acc: 0.6053
840/876 [===========================>..] - ETA: 0s - loss: 0.6681 - acc: 0.6119
876/876 [==============================] - 1s 597us/step - loss: 0.6700 - acc: 0.6073 - val_loss: 0.6583 - val_acc: 0.6347
Epoch 20/20

  5/876 [..............................] - ETA: 0s - loss: 0.6731 - acc: 0.6000
100/876 [==>...........................] - ETA: 0s - loss: 0.6944 - acc: 0.5500
190/876 [=====>........................] - ETA: 0s - loss: 0.6843 - acc: 0.5737
285/876 [========>.....................] - ETA: 0s - loss: 0.6805 - acc: 0.5825
380/876 [============>.................] - ETA: 0s - loss: 0.6787 - acc: 0.5868
470/876 [===============>..............] - ETA: 0s - loss: 0.6731 - acc: 0.6000
565/876 [==================>...........] - ETA: 0s - loss: 0.6671 - acc: 0.6142
660/876 [=====================>........] - ETA: 0s - loss: 0.6699 - acc: 0.6076
750/876 [========================>.....] - ETA: 0s - loss: 0.6697 - acc: 0.6080
840/876 [===========================>..] - ETA: 0s - loss: 0.6711 - acc: 0.6048
876/876 [==============================] - 1s 595us/step - loss: 0.6700 - acc: 0.6073 - val_loss: 0.6582 - val_acc: 0.6347

 32/219 [===>..........................] - ETA: 0s
219/219 [==============================] - 0s 41us/step
[0.6582215077256504, 0.6347031933531914]
[array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32), array([[0.6053798]], dtype=float32)]

Process finished with exit code 0
